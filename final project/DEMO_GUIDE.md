# æœŸæœ«å°ˆé¡Œå±•ç¤ºæŒ‡å—
# ===================

## ğŸ¯ ä¸‰ç¨®å±•ç¤ºæ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: å¿«é€Ÿ Demoï¼ˆæ¨è–¦ï¼ä¸éœ€ä¸‹è¼‰æ¨¡å‹ï¼‰
```powershell
# ä½¿ç”¨åˆæˆè³‡æ–™ï¼Œç«‹å³å±•ç¤º CUDA kernel æ•ˆèƒ½
$env:PATH = "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin;" + $env:PATH
python quick_demo.py
```

**å„ªé»**ï¼š
- âœ… ä¸éœ€ä¸‹è¼‰ä»»ä½•æ¨¡å‹
- âœ… åŸ·è¡Œè¶…å¿«ï¼ˆ30ç§’å…§å®Œæˆï¼‰
- âœ… å®Œæ•´å±•ç¤º CUDA kernel åŠŸèƒ½å’Œæ•ˆèƒ½
- âœ… é©åˆç¾å ´ demo

**å±•ç¤ºå…§å®¹**ï¼š
- åŠŸèƒ½æ­£ç¢ºæ€§é©—è­‰
- ä¸‰ç¨®å¯¦ä½œæ¯”è¼ƒï¼ˆBaseline vs PyTorch vs CUDAï¼‰
- æ•ˆèƒ½æå‡æ•¸æ“š

---

### æ–¹æ¡ˆ 2: çœŸå¯¦ LLM Demoï¼ˆæ›´æœ‰èªªæœåŠ›ï¼‰

#### Step 1: å®‰è£ transformers
```powershell
pip install transformers accelerate sentencepiece
```

#### Step 2: åŸ·è¡Œ Demoï¼ˆæœƒè‡ªå‹•ä¸‹è¼‰æ¨¡å‹ï¼‰
```powershell
$env:PATH = "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin;" + $env:PATH
python demo_with_real_llm.py
```

**æ³¨æ„**ï¼š
- é¦–æ¬¡åŸ·è¡Œæœƒä¸‹è¼‰ TinyLlama-1.1Bï¼ˆç´„ 2GBï¼‰
- éœ€è¦ç´„ 5-10 åˆ†é˜ä¸‹è¼‰æ™‚é–“
- RTX 3060 12GB å®Œå…¨å¤ ç”¨

**å±•ç¤ºå…§å®¹**ï¼š
- çœŸå¯¦çš„ Speculative Decoding
- Draft model çŒœæ¸¬ â†’ Target model é©—è­‰
- é¡¯ç¤º acceptance rate
- å¯¦éš›ç”Ÿæˆæ–‡å­—

---

### æ–¹æ¡ˆ 3: å®Œæ•´ Benchmarkï¼ˆæœŸæœ«å ±å‘Šæ•¸æ“šï¼‰

```powershell
$env:PATH = "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin;" + $env:PATH
python benchmark_cuda_comparison.py
```

**å±•ç¤ºå…§å®¹**ï¼š
- ä¸åŒ batch size çš„æ•ˆèƒ½æ¯”è¼ƒ
- ä¸åŒ spec_len çš„æ•ˆèƒ½æ¯”è¼ƒ
- å¹³å‡åŠ é€Ÿæ¯”å’Œæœ€å¤§åŠ é€Ÿæ¯”

---

## ğŸ“Š æœŸæœ«å ±å‘Šå»ºè­°çµæ§‹

### 1. å•é¡Œæè¿°ï¼ˆ5 åˆ†é˜ï¼‰
- **Speculative Decoding æ˜¯ä»€éº¼**
  - Draft model (å°æ¨¡å‹) çŒœæ¸¬å¤šå€‹ tokens
  - Target model (å¤§æ¨¡å‹) é©—è­‰
  - Rejection Sampling ç¢ºä¿æ­£ç¢ºæ€§
  
- **ç‚ºä»€éº¼éœ€è¦å„ªåŒ–**
  - Baseline ä½¿ç”¨ Python for loop
  - O(K) æ¬¡ kernel launches
  - CPU-GPU åŒæ­¥æ˜¯ç“¶é ¸

### 2. è§£æ±ºæ–¹æ¡ˆï¼ˆ10 åˆ†é˜ï¼‰

#### æ–¹æ¡ˆ 1: PyTorch å‘é‡åŒ–
```python
# Before: O(K) kernel launches
for k in range(spec_len):
    accept = check_acceptance(k)  # Kernel 1
    if accept:
        output[k] = draft[k]      # Kernel 2
    else:
        break                     # CPU sync!

# After: O(1) kernel launches
accepts = check_all_acceptances()  # Single kernel
first_reject = find_first_false()  # Single kernel
output = gather_accepted()         # Single kernel
```

**çµæœ**: å¹³å‡ 9.5x åŠ é€Ÿ

#### æ–¹æ¡ˆ 2: CUDA C++ Kernelï¼ˆä½ çš„è²¢ç»ï¼ï¼‰
```cuda
// å–®ä¸€ kernelï¼Œæ¯å€‹ thread è™•ç†ä¸€å€‹ batch
__global__ void fused_rejection_sample_kernel(...) {
    int batch_idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    for (int k = 0; k < n_draft; k++) {
        if (accepted) {
            output[n_accepted++] = draft[k];
        } else {
            // Resample from adjusted distribution
            output[n_accepted++] = argmax(adjusted);
            break;  // âœ… Break åœ¨ GPU å…§ï¼
        }
    }
}
```

**é—œéµå‰µæ–°**:
- âœ… å–®ä¸€ kernel launch
- âœ… Early exit åœ¨ GPU å…§å®Œæˆ
- âœ… ç„¡ CPU-GPU åŒæ­¥

**çµæœ**: å¹³å‡ 11.95x åŠ é€Ÿï¼Œæœ€é«˜ 35.57x

### 3. å¯¦é©—çµæœï¼ˆ5 åˆ†é˜ï¼‰

**å±•ç¤º benchmark åœ–è¡¨**:
```
Batch Size | Baseline | PyTorch | CUDA  | CUDA Speedup
-----------|----------|---------|-------|-------------
1          | 1.48ms   | 1.17ms  | 0.04ms| 35.57x ğŸ”¥
4          | 3.21ms   | 1.05ms  | 0.94ms| 3.41x
16         | 14.74ms  | 1.22ms  | 2.11ms| 6.97x
64         | 66.92ms  | 3.04ms  | 3.21ms| 20.87x
```

**é‡é»èªªæ˜**:
- å° batch æ™‚ CUDA kernel å„ªå‹¢æ˜é¡¯ï¼ˆ35x!ï¼‰
- å¤§ batch æ™‚å…©è€…éƒ½å¾ˆå¿«ï¼ˆkernel overhead ç›¸å°ä¸é‡è¦ï¼‰
- è­‰æ˜äº† CPU-GPU åŒæ­¥ç¢ºå¯¦æ˜¯ç“¶é ¸

### 4. Demo å±•ç¤ºï¼ˆ5 åˆ†é˜ï¼‰

**é¸é … A: Quick Demo**
```powershell
python quick_demo.py
```
- å±•ç¤ºä¸‰ç¨®å¯¦ä½œçš„è¼¸å‡ºä¸€è‡´æ€§
- å±•ç¤ºæ•ˆèƒ½å·®ç•°
- è§£é‡‹ç‚ºä»€éº¼ CUDA æ›´å¿«

**é¸é … B: Real LLM Demo**ï¼ˆå¦‚æœæ™‚é–“å¤ ï¼‰
```powershell
python demo_with_real_llm.py
```
- å±•ç¤ºçœŸå¯¦çš„ Speculative Decoding
- é¡¯ç¤º acceptance rate
- å¯¦éš›ç”Ÿæˆæ–‡å­—

### 5. çµè«–ï¼ˆ2 åˆ†é˜ï¼‰

**æˆæœ**:
- âœ… å¯¦ä½œäº†ä¸‰ç¨®ç‰ˆæœ¬çš„ Rejection Sampler
- âœ… æœ€é«˜é”åˆ° 35.57x åŠ é€Ÿ
- âœ… çœŸæ­£çš„ CUDA C++ kernelï¼ˆä¸æ˜¯ Python wrapperï¼‰

**å­¸åˆ°çš„**:
- CPU-GPU åŒæ­¥æ˜¯æ•ˆèƒ½æ®ºæ‰‹
- å‘é‡åŒ–å¯ä»¥å¤§å¹…æ¸›å°‘ kernel launches
- CUDA kernel èƒ½æ¶ˆé™¤æ‰€æœ‰åŒæ­¥

**æœªä¾†æ”¹é€²**:
- æ”¯æ´æ›´è¤‡é›œçš„ sampling ç­–ç•¥ï¼ˆtop-k, nucleusï¼‰
- å„ªåŒ–è¨˜æ†¶é«”å­˜å–æ¨¡å¼ï¼ˆshared memoryï¼‰
- æ”¯æ´æ›´å¤§çš„ batch size

---

## ğŸ¬ Demo è…³æœ¬å»ºè­°

### é–‹å ´ï¼ˆ30 ç§’ï¼‰
"å¤§å®¶å¥½ï¼Œä»Šå¤©è¦å±•ç¤ºçš„æ˜¯ Speculative Decoding ä¸­çš„ Rejection Sampling å„ªåŒ–ã€‚
é€™æ˜¯ LLM æ¨ç†åŠ é€Ÿçš„é‡è¦æŠ€è¡“ã€‚"

### å•é¡Œèªªæ˜ï¼ˆ1 åˆ†é˜ï¼‰
"Baseline å¯¦ä½œä½¿ç”¨ Python for loopï¼Œæ¯æ¬¡è¿´åœˆéƒ½è¦ launch kernel ä¸¦åŒæ­¥ CPU-GPUã€‚
é€™é€ æˆåš´é‡çš„æ•ˆèƒ½ç“¶é ¸ã€‚"

[å±•ç¤º baseline ç¨‹å¼ç¢¼ç‰‡æ®µ]

### è§£æ±ºæ–¹æ¡ˆï¼ˆ2 åˆ†é˜ï¼‰
"æˆ‘å€‘é–‹ç™¼äº†å…©å€‹è§£æ±ºæ–¹æ¡ˆï¼š
1. PyTorch å‘é‡åŒ– - æ¶ˆé™¤ Python loop
2. CUDA C++ Kernel - çœŸæ­£çš„ GPU èåˆ"

[å±•ç¤º CUDA kernel ç¨‹å¼ç¢¼]

"é—œéµæ˜¯æŠŠ early exit ç§»åˆ° GPU å…§éƒ¨åŸ·è¡Œ"

### å¯¦éš›å±•ç¤ºï¼ˆ2 åˆ†é˜ï¼‰
```powershell
python quick_demo.py
```

"å¯ä»¥çœ‹åˆ°ï¼š
- ä¸‰ç¨®å¯¦ä½œè¼¸å‡ºå®Œå…¨ä¸€è‡´ âœ…
- PyTorch å¿«äº† 9.5 å€
- CUDA kernel å¿«äº† 11.95 å€ï¼Œåœ¨ batch=1 æ™‚ç”šè‡³é”åˆ° 35 å€ï¼"

### Q&A é æœŸå•é¡Œ

**Q: ç‚ºä»€éº¼ä¸æ˜¯æ‰€æœ‰æƒ…æ³éƒ½æ¯” PyTorch å¿«ï¼Ÿ**
A: åœ¨å¤§ batch size æ™‚ï¼Œè¨ˆç®—é‡è®Šå¤§ï¼Œkernel launch overhead ç›¸å°ä¸é‡è¦ï¼Œ
   æ‰€ä»¥å…©è€…æ•ˆèƒ½æ¥è¿‘ã€‚ä½† CUDA kernel åœ¨å° batch æ™‚å„ªå‹¢æ˜é¡¯ã€‚

**Q: èƒ½ç”¨åœ¨çœŸå¯¦çš„ LLM å—ï¼Ÿ**
A: å¯ä»¥ï¼æˆ‘å€‘ä¹Ÿå¯¦ä½œäº†çœŸå¯¦ LLM ç‰ˆæœ¬ï¼ˆdemo_with_real_llm.pyï¼‰ï¼Œ
   ä½¿ç”¨ TinyLlama-1.1B é€²è¡Œå¯¦éš›çš„ Speculative Decodingã€‚

**Q: é€™å€‹æŠ€è¡“çš„å¯¦éš›æ‡‰ç”¨æ˜¯ä»€éº¼ï¼Ÿ**
A: Speculative Decoding è¢«ç”¨åœ¨å¾ˆå¤š LLM serving ç³»çµ±ä¸­ï¼Œ
   ä¾‹å¦‚ vLLMã€TensorRT-LLM ç­‰ï¼Œå¯ä»¥è®“å¤§æ¨¡å‹æ¨ç†å¿« 2-3 å€ã€‚

---

## ğŸš€ æœ€å¾Œå»ºè­°

**ç¾å ´ Demo ç”¨**: `quick_demo.py`
- ä¸éœ€ä¸‹è¼‰æ¨¡å‹
- åŸ·è¡Œå¿«é€Ÿ
- çµæœæ¸…æ™°

**å ±å‘Šæˆªåœ–ç”¨**: `benchmark_cuda_comparison.py`
- å®Œæ•´çš„æ•ˆèƒ½æ•¸æ“š
- å¯ä»¥åšæˆåœ–è¡¨

**åŠ åˆ†é …**: `demo_with_real_llm.py`
- å¦‚æœè©•å¯©å•"èƒ½ç”¨çœŸå¯¦æ¨¡å‹å—"
- å¯ä»¥èªª"å¯ä»¥ï¼æˆ‘å€‘ä¹Ÿåšäº†"
- å¢åŠ å°ˆæ¡ˆå®Œæ•´åº¦

**é‡é»**: å¼·èª¿ä½ å¯«çš„æ˜¯**çœŸæ­£çš„ CUDA C++ code**ï¼Œä¸æ˜¯ PyTorch wrapperï¼

ç¥ä½ æœŸæœ«å ±å‘Šé †åˆ©ï¼ğŸ‰
